{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64429aaa",
   "metadata": {},
   "source": [
    "# Homesite Quote Conversion <a id='goback'> </a>\n",
    "![image.png](Homesite_image.png) \n",
    "\n",
    "**Background** <br>\n",
    "This dataset represents the activity of a large number of customers who are interested in buying policies from Homesite. Each QuoteNumber corresponds to a potential customer and the QuoteConversion_Flag indicates whether the customer purchased a policy.\n",
    "<br>\n",
    "The provided features are anonymized and provide a rich representation of the prospective customer and policy. They include specific coverage information, sales information, personal information, property information, and geographic information. Your task is to predict QuoteConversion_Flag for each QuoteNumber in the test set.\n",
    "\n",
    "**References** <br>\n",
    "    - [Pandas Library](https://pandas.pydata.org/docs/index.html) <br>\n",
    "    - [SkLearn Library](https://scikit-learn.org/stable/) <br>\n",
    "    - [SMOTE API](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTE.html) <br>\n",
    "    - [Stacking Library](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html) <br>\n",
    "    - [Kaggle Dataset](https://www.kaggle.com/competitions/homesite-quote-conversion/data?select=test.csv.zip) <br>\n",
    "\n",
    "**Notebook Index**\n",
    "- [Data Import](#dataimport)\n",
    "- [Data Preprocessing](#preprocess)\n",
    "    - [One Hot Encoding : Categorical Values](#ohe)\n",
    "    - [Handling Imbalanced Datasets](#imbalance)\n",
    "- [Effect of SMOTE on a classification model ](#smote)\n",
    "- [Accuracy Comparison](#acccompare)\n",
    "    - [Multiple Model Development](#multiple)\n",
    "    - [Ensemble Method : Stacking](#ensemble)\n",
    "    - [Accuracy Report](#acc)\n",
    "- [Kaggle Submission](#kag)\n",
    "    - [Multiple Model Development with HyperParameter Tuning](#multiple2)\n",
    "    - [Ensemble Method : Stacking](#ensemble2)\n",
    "    - [Kaggle Report](#kag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sn\n",
    "\n",
    "# Imbalanced Data\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,NearMiss\n",
    "\n",
    "# Machine Learning \n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,roc_auc_score,roc_curve,mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Hyper Parameter Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "\n",
    "# Stacking\n",
    "from vecstack import stacking\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Function to evaluate the model results\n",
    "def evaluate_model(model,xtrain,xtest,ytrain,ytest):\n",
    "    model.fit(xtrain,ytrain)\n",
    "    ypred=model.predict(xtest)\n",
    "    \n",
    "    print(model)\n",
    "    print(\"Testing Accuracy Score: \",accuracy_score(ytest,ypred))\n",
    "    print()\n",
    "    print(\"Classification Report: \\n\",classification_report(ytest,ypred))\n",
    "    print()\n",
    "\n",
    "# SMOTEing on Training data only and Accuracy with YTest\n",
    "def evaluate_modeL_smote(model,X,Y,k):\n",
    "    #If k=0 , no oversmapling required\n",
    "    \n",
    "    Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,Y,test_size=0.3)\n",
    "    \n",
    "    # SMOTEingonly on Train part of Train_df\n",
    "    if k!=0: \n",
    "        sm=SMOTE(sampling_strategy=k)\n",
    "        SMOTE_X,SMOTE_Y=sm.fit_resample(Xtrain,Ytrain)\n",
    "    else:\n",
    "        SMOTE_X=Xtrain\n",
    "        SMOTE_Y=Ytrain\n",
    "    \n",
    "    # Fitting using SMOTE_X,SMOTE_Y\n",
    "    model.fit(SMOTE_X,SMOTE_Y)\n",
    "    YPred=model.predict(Xtest)\n",
    "    \n",
    "    print(model)\n",
    "    print(\"\\nSMOTE sampling_strategy:\",k)\n",
    "    print(\"Testing Accuracy Score: \",accuracy_score(Ytest,YPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c424d6",
   "metadata": {},
   "source": [
    "## Data Import <a id='dataimport'> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingFile_loc=r'Data/RevisedHomesiteTrain1.csv'\n",
    "Train_df=pd.read_csv(TrainingFile_loc)\n",
    "\n",
    "TestingFile_loc=r'Data/RevisedHomesiteTest1.csv'\n",
    "Test_df=pd.read_csv(TestingFile_loc)\n",
    "\n",
    "Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f4ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd9a0bd",
   "metadata": {},
   "source": [
    "`[Go Back to Index](#goback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e4010",
   "metadata": {},
   "source": [
    "## Data Preprocessing <a id=\"preprocess\"> </a>\n",
    "One Hot Encoding for Categorical Datapoints <a id='ohe'> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue in Encoding GrographicalField64 \n",
    "# Drop\n",
    "Test_df.drop([\"GeographicField64_CA\",\"GeographicField64_IL\",\"GeographicField64_NJ\",\"GeographicField64_TX\"],axis=1,inplace=True)\n",
    "\n",
    "# Perform OneHotEncoding to Code location IL,NJ,TX,CA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "GeoFieldEnc=OneHotEncoder(sparse=False,handle_unknown='ignore')\n",
    "EncodedValues=pd.DataFrame(GeoFieldEnc.fit_transform(Test_df[['GeographicField64']]),\n",
    "                           columns=GeoFieldEnc.get_feature_names_out())\n",
    "\n",
    "Test_df=pd.concat([Test_df,EncodedValues],axis=1)\n",
    "Test_df\n",
    "#Dropping a categorical column \n",
    "Test_df.drop(\"GeographicField64\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf25094",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b60d59",
   "metadata": {},
   "source": [
    "Successfully encoded GrographicalField64!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc2e215",
   "metadata": {},
   "source": [
    "Drop any Row Duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d3c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.drop_duplicates()\n",
    "Train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5219f",
   "metadata": {},
   "source": [
    "No Row Duplicates found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80475f",
   "metadata": {},
   "source": [
    "Search for any null values in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db865d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d9edcc",
   "metadata": {},
   "source": [
    "No Null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38eb8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Train_df.drop(\"QuoteConversion_Flag\",axis=1)\n",
    "Y=Train_df[\"QuoteConversion_Flag\"]\n",
    "\n",
    "Y.value_counts(), Y.value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3eeffd",
   "metadata": {},
   "source": [
    "`[Go Back to Index](#goback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ede94e",
   "metadata": {},
   "source": [
    "### Handling Imbalanced Datasets <a id='imbalance'> </a>\n",
    "- Random Under Sampling\n",
    "- Random Over Sampling\n",
    "- **SMOTE**: Synthetic Minority Oversampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffeb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Under-Sampling\n",
    "# rus=RandomUnderSampler(sampling_strategy=1)\n",
    "# X_rus,Y_rus=rus.fit_resample(X,Y)\n",
    "# Y_rus.value_counts(), Y_rus.value_counts().plot.pie()\n",
    "\n",
    "# # Near Miss Under Sampling \n",
    "# # Three Methods : \n",
    "# Nearmiss1: K nearest neighbours having smallest avg distance,\n",
    "# Nearmiss K neighbours farthest having smallest avg distance2,nearmiss 3\n",
    "# nmus=NearMiss(sampling_strategy=1)\n",
    "# X_nmus,Y_nmus=nmus.fit_resample(X,Y)\n",
    "# Y_nmus.value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d390ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Over-Sampling\n",
    "# rus=RandomOverSampler(sampling_strategy=1)\n",
    "# X_ros,Y_ros=rus.fit_resample(X,Y)\n",
    "# Y_ros.value_counts(), Y_ros.value_counts().plot.pie()\n",
    "\n",
    "#Synethetic Minority Oversampling Technique : SMOTE\n",
    "sm=SMOTE(sampling_strategy=1)\n",
    "X_sm,Y_sm=sm.fit_resample(X,Y)\n",
    "Y_sm.value_counts(), Y_sm.value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0c0b34",
   "metadata": {},
   "source": [
    "`[Go Back to Index](#goback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ae9ad",
   "metadata": {},
   "source": [
    "## Effect of SMOTE on a classification model <a id='smote'> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28655708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model1 : Decision Tree\n",
    "M1=DecisionTreeClassifier()\n",
    "#No SMOTE\n",
    "evaluate_modeL_smote(M1,X,Y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2197021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model1 : Decision Tree\n",
    "M12=DecisionTreeClassifier()\n",
    "evaluate_modeL_smote(M12,X,Y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M13=DecisionTreeClassifier()\n",
    "evaluate_modeL_smote(M13,X,Y,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16dcdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "M14=DecisionTreeClassifier()\n",
    "evaluate_modeL_smote(M14,X,Y,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3321629",
   "metadata": {},
   "source": [
    "`[Go Back to Index](#goback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d606467",
   "metadata": {},
   "source": [
    "## Accuracy Comparison <a id='acccompare'> </a>\n",
    "### Multiple Model Development <a id='multiple'> </a>\n",
    "- We use a sampling_strategy of 1 as it provides us with equal instances of both classes\n",
    "- Developing 5 Models : Decision Tree, Random Forest, Support Vector Machine, KNN Classfier, Neural Nets MPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a0d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#With Test_Train Split function\n",
    "Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,Y,test_size=0.3)\n",
    "\n",
    "sm=SMOTE(sampling_strategy=1)\n",
    "SMOTE_X,SMOTE_Y=sm.fit_resample(Xtrain,Ytrain)\n",
    "\n",
    "# Model1 : Decision Tree\n",
    "M1=DecisionTreeClassifier()\n",
    "evaluate_model(M1,SMOTE_X,Xtest,SMOTE_Y,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbe037",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Model2 : Random Forest Classifier\n",
    "M2=RandomForestClassifier()\n",
    "evaluate_model(M2,SMOTE_X,Xtest,SMOTE_Y,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89025052",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Model3 : Support Vector Machine\n",
    "M3=LinearSVC()\n",
    "evaluate_model(M3,SMOTE_X,Xtest,SMOTE_Y,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef9b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Model4 : KNN Classifier\n",
    "M4=KNeighborsClassifier()\n",
    "evaluate_model(M4,SMOTE_X,Xtest,SMOTE_Y,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed2f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model5 : Neural Nets\n",
    "M5=MLPClassifier()\n",
    "evaluate_model(M5,SMOTE_X,Xtest,SMOTE_Y,Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f802c75",
   "metadata": {},
   "source": [
    "`[Go Back to Index](#goback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54bb7f3",
   "metadata": {},
   "source": [
    "### Ensemble Method <a id='ensemble'> </a>\n",
    "Stacking 5 models and taking RandomForestClassifier as Top Level Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Stacking 5 models using just Train_df\n",
    "\n",
    "print(\"__________________________________________STACKING with TestTrainSplit______________________________________________\")\n",
    "\n",
    "# models=[M1,M2,M3,M4,M5]\n",
    "models=[DecisionTreeClassifier(),RandomForestClassifier(),LinearSVC(),KNeighborsClassifier(),MLPClassifier()]\n",
    "\n",
    "S_train,S_Test=stacking(models,\n",
    "                        SMOTE_X,SMOTE_Y,Xtest,\n",
    "                        shuffle=True,\n",
    "                        regression=False,\n",
    "                        metric=accuracy_score,\n",
    "                        verbose=2\n",
    "                       )\n",
    "\n",
    "FinalModel=RandomForestClassifier()\n",
    "FinalModel.fit(S_train,SMOTE_Y)\n",
    "ypred_train=FinalModel.predict(S_train)\n",
    "ypred_test=FinalModel.predict(S_Test)\n",
    "\n",
    "print(\"Training Accuracy:\",accuracy_score(SMOTE_Y,ypred_train))\n",
    "print(\"Testing Accuracy:\",accuracy_score(Ytest,ypred_test))\n",
    "    \n",
    "print(\"Mean Square Error Train:\",mean_squared_error(SMOTE_Y,ypred_train))\n",
    "print(\"Mean Square Error Test:\",mean_squared_error(Ytest,ypred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56026778",
   "metadata": {},
   "source": [
    "`[Go Back to Index](#goback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a749f",
   "metadata": {},
   "source": [
    "## Accuracy Comparison <a id='acc'> </a>\n",
    "Using train_test_split on Train_df\n",
    "\n",
    "|S No.| Model Name | Type of Model | SMOTE strategy | HyperParameter Tuning | Accuracy  |\n",
    "|:-:| :---- | :---: | :---: |:---: |:---: |\n",
    "|1.| Decision Tree M1 | Individual |1|None| 0.87 |\n",
    "|2.| Random Forest Classifier M2 | Individual |1|None| <span style=\"color:red\">0.89</span> |\n",
    "|3.| LinearSVC Classifier M3 | Individual |1|None| 0.34 |\n",
    "|4.| KNeighborsClassifier M4 | Individual |1|None| 0.57 |\n",
    "|5.| MLP Classifier M5 | Individual |1|None| 0.80 |\n",
    "| | | | | | |\n",
    "|6.| **RandomForestClassifier** | **Stacked** |**1**|**None**| **0.89** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c97b89f",
   "metadata": {},
   "source": [
    "`[Go Back to Index](#goback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0267fba2",
   "metadata": {},
   "source": [
    "## Kaggle Submission <a id='kag'> </a>\n",
    "### Multiple Model Development <a id='multiple2'> </a>\n",
    "- Training models using SMOTEd Training data: X_sm, Y_sm <br>\n",
    "- Testing models using Test_df <br>\n",
    "- Sampling_strategy of 1 has been used for X_sm,Y_sm\n",
    "- Developing 5 Models : Decision Tree, Random Forest, Support Vector Machine, KNN Classfier, Neural Nets MPT\n",
    "- Hyper Parameter Tuning using RandomizedSeachCV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f05242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Decision Tree\n",
    "M6=DecisionTreeClassifier()\n",
    "# M6.fit(X_sm,Y_sm)\n",
    "\n",
    "# RandomCV Hyper Parameter Tuning\n",
    "param6={'criterion':['gini', 'entropy'],\n",
    "        'splitter':['best','random'],\n",
    "       'max_depth':range(1,20,1)}\n",
    "rcv=RandomizedSearchCV(M6,param6,verbose=2)\n",
    "rcv.fit(X_sm,Y_sm)\n",
    "print(\"Best set of parameters for dt: \",rcv.best_params_,\n",
    "      \"\\nBest Score : \",rcv.best_score_)\n",
    "parambest=rcv.best_params_\n",
    "\n",
    "M6=DecisionTreeClassifier(**parambest)\n",
    "M6.fit(X_sm,Y_sm)\n",
    "Output6=M6.predict_proba(Test_df)\n",
    "\n",
    "# Export as CSV\n",
    "sub=pd.read_csv(\"sample_submission.csv\")\n",
    "output=pd.concat([sub[\"QuoteNumber\"],pd.DataFrame(Output6[:,1],columns=[\"QuoteConversion_Flag\"])],axis=1)\n",
    "output.to_csv(\"M6_KaggleSubmissionAssignment3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07cdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random Forest\n",
    "M7=RandomForestClassifier()\n",
    "# M7.fit(X_sm,Y_sm)\n",
    "\n",
    "# RandomCV Hyper Parameter Tuning\n",
    "param7={'n_estimators':range(10,200,2),\n",
    "        'criterion':['gini', 'entropy'],\n",
    "       'max_depth':range(1,20,2)}\n",
    "rcv7=RandomizedSearchCV(M7,param7,verbose=2)\n",
    "rcv7.fit(X_sm,Y_sm)\n",
    "print(\"Best set of parameters for dt: \",rcv7.best_params_,\n",
    "      \"\\nBest Score : \",rcv7.best_score_)\n",
    "parambest=rcv7.best_params_\n",
    "\n",
    "M7=RandomForestClassifier(**parambest)\n",
    "M7.fit(X_sm,Y_sm)\n",
    "Output7=M7.predict_proba(Test_df)\n",
    "\n",
    "# Export as CSV\n",
    "sub=pd.read_csv(\"sample_submission.csv\")\n",
    "output=pd.concat([sub[\"QuoteNumber\"],pd.DataFrame(Output7[:,1],columns=[\"QuoteConversion_Flag\"])],axis=1)\n",
    "output.to_csv(\"M7_KaggleSubmissionAssignment3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c55cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Linear SVM\n",
    "M8=LinearSVC()\n",
    "# M8.fit(X_sm,Y_sm)\n",
    "\n",
    "# RandomCV Hyper Parameter Tuning\n",
    "param8={'max_iter':range(200,2000,200)}\n",
    "\n",
    "rcv8=RandomizedSearchCV(M8,param8,verbose=2)\n",
    "rcv8.fit(X_sm,Y_sm)\n",
    "print(\"Best set of parameters for dt: \",rcv8.best_params_,\n",
    "      \"\\nBest Score : \",rcv8.best_score_)\n",
    "parambest=rcv8.best_params_\n",
    "\n",
    "M8=LinearSVC(**parambest)\n",
    "M8.fit(X_sm,Y_sm)\n",
    "Output8=M8.predict(Test_df)\n",
    "\n",
    "# Export as CSV\n",
    "sub=pd.read_csv(\"sample_submission.csv\")\n",
    "output=pd.concat([sub[\"QuoteNumber\"],pd.DataFrame(Output8,columns=[\"QuoteConversion_Flag\"])],axis=1)\n",
    "output.to_csv(\"M8_KaggleSubmissionAssignment3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1678c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# KNN Classifier\n",
    "M9=KNeighborsClassifier()\n",
    "M9.fit(X_sm,Y_sm)\n",
    "\n",
    "# RandomCV Hyper Parameter Tuning\n",
    "param9={'n_neighbors':range(3,13,2),\n",
    "        'weights':['uniform', 'distance'],\n",
    "       'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "rcv9=RandomizedSearchCV(M9,param9,verbose=2)\n",
    "rcv9.fit(X_sm,Y_sm)\n",
    "print(\"Best set of parameters for dt: \",rcv9.best_params_,\n",
    "      \"\\nBest Score : \",rcv9.best_score_)\n",
    "parambest=rcv9.best_params_\n",
    "\n",
    "M9=KNeighborsClassifier(**parambest)\n",
    "M9.fit(X_sm,Y_sm)\n",
    "Output9=M9.predict_proba(Test_df)\n",
    "\n",
    "# Export as CSV\n",
    "sub=pd.read_csv(\"sample_submission.csv\")\n",
    "output=pd.concat([sub[\"QuoteNumber\"],pd.DataFrame(Output9[:,1],columns=[\"QuoteConversion_Flag\"])],axis=1)\n",
    "output.to_csv(\"M9_KaggleSubmissionAssignment3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c0fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# MLP Classifier\n",
    "M10=MLPClassifier()\n",
    "# M10.fit(X_sm,Y_sm)\n",
    "\n",
    "# RandomCV Hyper Parameter Tuning\n",
    "param10={'hidden_layer_sizes':[(10,),(20,),(40,),(60,),(80,),(100,)],\n",
    "        'activation':['identity', 'logistic','tanh','relu'],\n",
    "        'solver':['sgd','adam'],\n",
    "        'learning_rate':['constant', 'invscaling','adaptive']}\n",
    "rcv10=RandomizedSearchCV(M10,param10,verbose=2)\n",
    "rcv10.fit(X_sm,Y_sm)\n",
    "print(\"Best set of parameters for dt: \",rcv10.best_params_,\n",
    "      \"\\nBest Score : \",rcv10.best_score_)\n",
    "parambest=rcv10.best_params_\n",
    "\n",
    "M10=MLPClassifier(**parambest)\n",
    "M10.fit(X_sm,Y_sm)\n",
    "Output10=M10.predict_proba(Test_df)\n",
    "\n",
    "# Export as CSV\n",
    "sub=pd.read_csv(\"sample_submission.csv\")\n",
    "output=pd.concat([sub[\"QuoteNumber\"],pd.DataFrame(Output10[:,1],columns=[\"QuoteConversion_Flag\"])],axis=1)\n",
    "output.to_csv(\"M10_KaggleSubmissionAssignment3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e763a7aa",
   "metadata": {},
   "source": [
    "`[Go Back to Index](#goback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce2dcf",
   "metadata": {},
   "source": [
    "### Ensemble Method <a id='ensemble2'> </a>\n",
    "Stacking 5 models and taking RandomForestClassifier and DecisionTree as Top Level Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5428e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking\n",
    "# Level 0 Models\n",
    "models=[RandomForestClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        KNeighborsClassifier(),\n",
    "        LinearSVC(),\n",
    "        MLPClassifier()]\n",
    "\n",
    "# We can also use our hyper parameter tuned individual modesl as input for stacking\n",
    "# models=[M6,M7,M8,M9,M10]\n",
    "# models=[M6,M7,M10]\n",
    "\n",
    "S_Train_hp,S_Test_hp=stacking(models,\n",
    "                             X_sm,Y_sm,Test_df,\n",
    "                             shuffle=True,\n",
    "                             stratified=True,\n",
    "                             n_folds=4,\n",
    "                             regression=False,\n",
    "                             metric=accuracy_score,\n",
    "                             verbose=2)\n",
    "print('Stacking Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ad867",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Decision Tree Level 1 Model\n",
    "FinalModel_dt_hp=DecisionTreeClassifier()\n",
    "FinalModel_dt_hp.fit(S_Train_hp,Y_sm)\n",
    "\n",
    "# RandomCV Hyper Parameter Tuning\n",
    "final_param={'criterion':['gini', 'entropy'],\n",
    "             'max_depth':range(1,20,2)}\n",
    "\n",
    "rcv=RandomizedSearchCV(FinalModel_dt_hp,final_param,verbose=2)\n",
    "rcv.fit(S_Train_hp,Y_sm)\n",
    "print(\"Best set of parameters for dt: \",rcv.best_params_,\n",
    "      \"\\nBest Score : \",rcv.best_score_)\n",
    "parambest=rcv.best_params_\n",
    "\n",
    "FinalModel_dt_hp=DecisionTreeClassifier(**parambest)\n",
    "FinalModel_dt_hp.fit(S_Train_hp,Y_sm)\n",
    "\n",
    "OutputFinal=FinalModel_dt_hp.predict_proba(S_Test_hp)\n",
    "\n",
    "# Export as CSV\n",
    "sub=pd.read_csv(\"sample_submission.csv\")\n",
    "output=pd.concat([sub[\"QuoteNumber\"],pd.DataFrame(OutputFinal[:,1],columns=[\"QuoteConversion_Flag\"])],axis=1)\n",
    "output.to_csv(\"Final_dt_KaggleSubmissionAssignment3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa5a851",
   "metadata": {},
   "source": [
    "`[Go Back to Index](#goback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random Forest Level 1 Model\n",
    "FinalModel_rf_hp=RandomForestClassifier()\n",
    "FinalModel_rf_hp.fit(S_Train_hp,Y_sm)\n",
    "\n",
    "# RandomCV Hyper Parameter Tuning\n",
    "final_param={'n_estimators':range(10,200,10),\n",
    "             'criterion':['gini', 'entropy'],\n",
    "             'max_depth':range(1,20,2)}\n",
    "\n",
    "rcv=RandomizedSearchCV(FinalModel_rf_hp,final_param,verbose=2)\n",
    "rcv.fit(S_Train_hp,Y_sm)\n",
    "print(\"Best set of parameters for dt: \",rcv.best_params_,\n",
    "      \"\\nBest Score : \",rcv.best_score_)\n",
    "parambest=rcv.best_params_\n",
    "\n",
    "FinalModel_rf_hp=RandomForestClassifier(**parambest)\n",
    "FinalModel_rf_hp.fit(S_Train_hp,Y_sm)\n",
    "\n",
    "OutputFinal=FinalModel_rf_hp.predict_proba(S_Test_hp)\n",
    "\n",
    "# Export as CSV\n",
    "sub=pd.read_csv(\"sample_submission.csv\")\n",
    "output=pd.concat([sub[\"QuoteNumber\"],pd.DataFrame(OutputFinal[:,1],columns=[\"QuoteConversion_Flag\"])],axis=1)\n",
    "output.to_csv(\"Final_rf_KaggleSubmissionAssignment3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f76fab5",
   "metadata": {},
   "source": [
    "`[Go Back to Index](#goback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c2c13",
   "metadata": {},
   "source": [
    "### Kaggle Score Comparison <a id='kag2'> </a>\n",
    "Final Kaggle Scores for each Individual Hyperparameter tuned model and Stacked HyperParameter tuned model\n",
    "\n",
    "| Model Name | Type of Model |SMOTE strategy|HyperParameter Tuning| Kaggle Score |\n",
    "| :---: | :---: | :---: |:---: |:---: |\n",
    "| Decision Tree M6 | Individual | 1 |RandomizedSearchCV| 0.90 |\n",
    "| Random Forest M7 | Individual | 1 |RandomizedSearchCV| <span style=\"color:red\"> 0.94 </span>|\n",
    "| Linear SVC M8 | Individual | 1 |RandomizedSearchCV| 0.64 |\n",
    "| KNN Classifier M9 | Individual |1|RandomizedSearchCV| 0.50 |\n",
    "| MLP Classifier M10 | Individual |1|RandomizedSearchCV| 0.68 |\n",
    "| | | | |\n",
    "| **Decision Tree** | Stacked |1|RandomizedSearchCV| **0.85** |\n",
    "| **Random Forest** | Stacked |1|RandomizedSearchCV| **0.85** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf8ea8",
   "metadata": {},
   "source": [
    "`[Go Back to Index](#goback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
